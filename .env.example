# Meeting Recap App Configuration
# Copy this file to .env and update with your settings

# Ollama Server Configuration
# Default: localhost (requires Ollama to be running locally)
# For remote: http://<remote-ip>:11434
OLLAMA_HOST=http://localhost:11434

# Whisper Transcription Server (optional)
# For local transcription: comment out this line or leave blank
# For remote GPU transcription: http://<remote-ip>:9000
WHISPER_HOST=http://localhost:9000

# Output Directory
# Where transcripts, analysis, and recaps will be saved
OUTPUT_DIR=~/Documents/Meeting Recaps

# Whisper Model Size
# Options: tiny, base, small, medium, large
WHISPER_MODEL=medium

# Ollama Model
# Options: gemma3n:latest, llama3:latest, llama3.2:3b, etc.
OLLAMA_MODEL=gemma3n:latest
